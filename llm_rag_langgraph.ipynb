{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a llm and rag  workflow with groq using langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import Graph\n",
    "from IPython.display import display,Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model=\"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(AgentState):\n",
    "    messages=AgentState[\"messages\"]\n",
    "    question=messages[-1]\n",
    "    response=llm.invoke(question)\n",
    "    AgentState[\"messages\"].append(response.content)\n",
    "    return AgentState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_TOKEN\"]=os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=PyPDFLoader(\"C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf\")\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "documets=RecursiveCharacterTextSplitter(chunk_size=400,chunk_overlap=50).split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 0}, page_content='From Wikipedia, the free encyclopedia \\nAn illustration of main components of the \\ntransformer model from the paper \\n\"Attention Is All You Need\"[1] is a 2017 landmark[2][3] research paper in machine learning authored by \\neight scientists working at Google. The paper introduced a new deep learning architecture known as'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 0}, page_content='the transformer, based on the attention mechanism proposed in 2014 by Bahdanau et al.[4] It is \\nconsidered a foundational[5] paper in modern artificial intelligence, as the transformer approach has \\nbecome the main architecture of large language models like those based on GPT.[6][7] At the time, the'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 0}, page_content='focus of the research was on improving Seq2seq techniques for machine translation, but the authors \\ngo further in the paper, foreseeing the technique\\'s potential for other tasks like question \\nanswering and what is now known as multimodal Generative AI.[1] \\nThe paper\\'s title is a reference to the song \"All You Need Is Love\" by the Beatles.[8] The name'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 0}, page_content='\"Transformer\" was picked because Uszkoreit liked the sound of that word.[9] \\nAn early design document was titled \"Transformers: Iterative Self-Attention and Processing for \\nVarious Tasks\", and included an illustration of six characters from the Transformers animated show. \\nThe team was named Team Transformer.[8]'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 0}, page_content='The team was named Team Transformer.[8] \\nSome early examples that the team tried their Transformer architecture on included English-to-\\nGerman translation, generating Wikipedia articles on \"The Transformer\", and parsing. These \\nconvinced the team that the Transformer is a general purpose language model, and not just good for \\ntranslation.[9]'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 0}, page_content='translation.[9] \\nAs of 2024, the paper has been cited more than 100,000 times.[10] \\nFor their 100M-parameter Transformer model, they suggested learning rate should be linearly scaled \\nup from 0 to maximal value for the first part of the training (i.e. 2% of the total number of training \\nsteps), and to use dropout, to stabilize training. \\nAuthors \\n[edit]'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 0}, page_content='Authors \\n[edit] \\nThe authors of the paper are: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion \\nJones, Aidan Gomez, Lukasz Kaiser, and Illia Polosukhin. All eight authors were \"equal contributors\" \\nto the paper; the listed order was randomized. The Wired article highlights the group\\'s diversity:[8]'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 1}, page_content='Six of the eight authors were born outside the United States; the other two are children of two \\ngreen-card-carrying Germans who were temporarily in California and a first-generation American \\nwhose family had fled persecution, respectively. \\nBy 2023, all eight authors had left Google and founded their own AI start-ups (except Łukasz Kaiser, \\nwho joined OpenAI).[8][10] \\nHistorical context \\n[edit]'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 1}, page_content='Historical context \\n[edit] \\nMain articles: Transformer (deep learning architecture) § History, and Seq2seq § History \\nSee also: Timeline of machine learning \\nPredecessors \\n[edit] \\nFor many years, sequence modelling and generation was done by using plain recurrent neural \\nnetworks (RNNs). A well-cited early example was the Elman network (1990). In theory, the'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 1}, page_content=\"information from one token can propagate arbitrarily far down the sequence, but in practice \\nthe vanishing-gradient problem leaves the model's state at the end of a long sentence without \\nprecise, extractable information about preceding tokens. \\nA key breakthrough was LSTM (1995),[note 1] a RNN which used various innovations to overcome the\"),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 1}, page_content='vanishing gradient problem, allowing efficient learning of long-sequence modelling. One key \\ninnovation was the use of an attention mechanism which used neurons that multiply the outputs of \\nother neurons, so-called multiplicative units.[11] Neural networks using multiplicative units were later \\ncalled sigma-pi networks[12] or higher-order networks.[13] LSTM became the standard architecture for'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 1}, page_content='long sequence modelling until the 2017 publication of Transformers. However, LSTM still used \\nsequential processing, like most other RNNs.[note 2] Specifically, RNNs operate one token at a time \\nfrom first to last; they cannot operate in parallel over all tokens in a sequence. \\nModern Transformers overcome this problem, but unlike RNNs, they require computation time that'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 1}, page_content='is quadratic in the size of the context window. The linearly scaling fast weight controller (1992) learns \\nto compute a weight matrix for further processing depending on the input.[14] One of its two \\nnetworks has \"fast weights\" or \"dynamic links\" (1981).[15][16][17] A slow neural network learns by \\ngradient descent to generate keys and values for computing the weight changes of the fast neural'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 1}, page_content='network which computes answers to queries.[14] This was later shown to be equivalent to the \\nunnormalized linear Transformer.[18][19] \\nAttention with seq2seq \\n[edit] \\nMain article: Seq2seq § History \\nThe idea of encoder-decoder sequence transduction had been developed in the early 2010s (see \\nprevious papers[20][21]). The papers most commonly cited as the originators that produced seq2seq'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 1}, page_content='are two concurrently published papers from 2014.[20][21] \\nA 380M-parameter model for machine translation uses two long short-term memories (LSTM).[21] Its \\narchitecture consists of two parts. The encoder is an LSTM that takes in a sequence of tokens and'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 2}, page_content='turns it into a vector. The decoder is another LSTM that converts the vector into a sequence of \\ntokens. Similarly, another 130M-parameter model used gated recurrent units (GRU) instead of \\nLSTM.[20] Later research showed that GRUs are neither better nor worse than LSTMs for \\nseq2seq.[22][23] \\nThese early seq2seq models had no attention mechanism, and the state vector is accessible only'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 2}, page_content='after the last word of the source text was processed. Although in theory such a vector retains the \\ninformation about the whole original sentence, in practice the information is poorly preserved. This \\nis because the input is processed sequentially by one recurrent network into a fixed-size output \\nvector, which is then processed by another recurrent network into an output. If the input is long,'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 2}, page_content='then the output vector would not be able to contain all relevant information, degrading the output. \\nAs evidence, reversing the input sentence improved seq2seq translation.[24] \\nThe RNNsearch model introduced an attention mechanism to seq2seq for machine translation to \\nsolve the bottleneck problem (of the fixed-size output vector), allowing the model to process long-'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 2}, page_content='distance dependencies more easily. The name is because it \"emulates searching through a source \\nsentence during decoding a translation\".[4] \\nThe relative performances were compared between global (that of RNNsearch) and local (sliding \\nwindow) attention model architectures for machine translation, finding that mixed attention had'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 2}, page_content='higher quality than global attention, while local attention reduced translation time.[25] \\nIn 2016, Google Translate was revamped to Google Neural Machine Translation, which replaced the \\nprevious model based on statistical machine translation. The new model was a seq2seq model where \\nthe encoder and the decoder were both 8 layers of bidirectional LSTM.[26] It took nine months to'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 2}, page_content='develop, and it outperformed the statistical approach, which took ten years to develop.[27] \\nParallelizing attention \\n[edit] \\nMain article: Attention (machine learning) § History \\nSeq2seq models with attention (including self-attention) still suffered from the same issue with \\nrecurrent networks, which is that they are hard to parallelize, which prevented them to be'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 2}, page_content='accelerated on GPUs. In 2016, decomposable attention applied a self-attention mechanism \\nto feedforward networks, which are easy to parallelize, and achieved SOTA result in textual \\nentailment with an order of magnitude less parameters than LSTMs.[28] One of its authors, Jakob \\nUszkoreit, suspected that attention without recurrence is sufficient for language translation, thus the'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 2}, page_content='title \"attention is all you need\".[29] That hypothesis was against conventional wisdom of the time, and \\neven his father, a well-known computational linguist, was skeptical.[29] In the same year, self-attention \\n(called intra-attention or intra-sentence attention) was proposed for LSTMs.[30] \\nIn 2017, the original (100M-sized) encoder-decoder transformer model was proposed in the'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 2}, page_content='\"Attention is all you need\" paper. At the time, the focus of the research was on \\nimproving seq2seq for machine translation, by removing its recurrence to process all tokens in \\nparallel, but preserving its dot-product attention mechanism to keep its text processing \\nperformance.[1] Its parallelizability was an important factor to its widespread use in large neural \\nnetworks.[31] \\nAI boom era'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 2}, page_content='networks.[31] \\nAI boom era \\n[edit]'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 3}, page_content='Already in spring 2017, even before the \"Attention is all you need\" preprint was published, one of the \\nco-authors applied the \"decoder-only\" variation of the architecture to generate fictitious Wikipedia \\narticles.[32] Transformer architecture is now used in many generative models that contribute to the \\nongoing AI boom.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 3}, page_content='ongoing AI boom. \\nIn language modelling, ELMo (2018) was a bi-directional LSTM that produces contextualized word \\nembeddings, improving upon the line of research from bag of words and word2vec. It was followed \\nby BERT (2018), an encoder-only Transformer model.[33] In 2019 October, Google started using BERT'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 3}, page_content='to process search queries.[34] In 2020, Google Translate replaced the previous RNN-encoder–RNN-\\ndecoder model by a Transformer-encoder–RNN-decoder model.[35] \\nStarting in 2018, the OpenAI GPT series of decoder-only Transformers became state of the art \\nin natural language generation. In 2022, a chatbot based on GPT-3, ChatGPT, became unexpectedly'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 3}, page_content='popular,[36] triggering a boom around large language models.[37][38] \\nSince 2020, Transformers have been applied in modalities beyond text, including the vision \\ntransformer,[39] speech recognition,[40] robotics,[41] and multimodal.[42] The vision transformer, in turn, \\nstimulated new developments in convolutional neural networks.[43] Image and video generators'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langchain\\\\temp.pdf', 'page': 3}, page_content='like DALL-E (2021), Stable Diffusion 3 (2024),[44] and Sora (2024), are based on the Transformer \\narchitecture.')]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=FAISS.from_documents(embedding=embeddings,documents=documets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000024121E19040>, search_kwargs={})"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(AgentState):\n",
    "    messages=AgentState[\"messages\"]\n",
    "    question=messages[0]\n",
    "    #print(question)\n",
    "    template=\"\"\"Answer the following question based on the given context\n",
    "    {context}\n",
    "    Question:{question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt=ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    retrieval=prompt|llm|StrOutputParser()\n",
    "\n",
    "    response=retrieval.invoke({\"context\":retriever,\"question\":question})\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow=Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.graph.Graph at 0x241229be8a0>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"llm\",function_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.graph.Graph at 0x241229be8a0>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"rag\",function_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.graph.Graph at 0x241229be8a0>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(\"llm\",\"rag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.graph.Graph at 0x241229be8a0>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.set_entry_point(\"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.graph.Graph at 0x241229be8a0>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.set_finish_point(\"rag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "input={\"messages\":[\"what is transformer\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here the output is 'llm':\n",
      "----------\n",
      "{'messages': ['what is transformer', \"Let's break down transformers in the realm of artificial intelligence.\\n\\n**What is a Transformer?**\\n\\nAt its core, a transformer is a powerful type of neural network architecture specifically designed for processing sequential data, like text or time series.  They've revolutionized natural language processing (NLP) and are increasingly used in other fields.\\n\\n**Key Features:**\\n\\n* **Attention Mechanism:** This is the heart of a transformer. It allows the model to focus on specific parts of the input sequence that are most relevant to the task at hand. Imagine reading a sentence and naturally emphasizing certain words based on context – that's what attention does.\\n* **Encoder-Decoder Structure:** Transformers typically consist of two main parts:\\n    * **Encoder:**  Processes the input sequence, understanding its structure and meaning.\\n    * **Decoder:** Generates the output sequence, using the encoder's understanding of the input.\\n\\n* **Parallel Processing:** Unlike earlier recurrent neural networks (RNNs), transformers can process entire input sequences simultaneously. This makes them significantly faster for training and inference.\\n\\n**Why are Transformers So Powerful?**\\n\\n1. **Long-Range Dependencies:** They excel at capturing relationships between words that are far apart in a sentence, something RNNs struggled with.\\n\\n2. **Contextual Understanding:** Attention allows transformers to build a rich understanding of the context surrounding each word, leading to more accurate and nuanced language processing.\\n\\n3. **Transfer Learning:**  Pre-trained transformer models (like BERT, GPT-3, T5) have been trained on massive datasets and can be fine-tuned for specific tasks with relatively little additional data. This has democratized access to state-of-the-art NLP capabilities.\\n\\n**Examples of Transformer Applications:**\\n\\n* **Machine Translation:**  Translating text from one language to another.\\n* **Text Summarization:** Condensing large amounts of text into shorter summaries.\\n* **Question Answering:**  Finding answers to questions within a given text passage.\\n* **Chatbots:**  Creating conversational agents that can engage in natural-sounding dialogue.\\n* **Code Generation:**  Assisting programmers by generating code snippets.\\n\\n**In Essence:**\\n\\nTransformers are a game-changer in AI, enabling machines to understand and generate human language with unprecedented accuracy and fluency.\\n\\n\\nLet me know if you have any other questions or want to dive deeper into a specific aspect of transformers!\\n\"]} what is transformer\n",
      "here the output is 'rag':\n",
      "----------\n",
      "While the provided context mentions FAISS and HuggingFaceEmbeddings, it doesn't offer information about transformers. \n",
      "\n",
      "**Here's a general explanation of transformers:**\n",
      "\n",
      "Transformers are a type of neural network architecture that has revolutionized natural language processing (NLP). They are particularly good at understanding and generating human-like text.\n",
      "\n",
      "**Key features of transformers:**\n",
      "\n",
      "* **Attention mechanism:** This allows the model to focus on specific parts of the input sequence that are most relevant to the task at hand.\n",
      "* **Self-attention:**  Transformers can attend to different parts of the same input sequence, allowing them to capture complex relationships between words.\n",
      "* **Encoder-decoder structure:**  Many transformer models have an encoder that processes the input text and a decoder that generates the output text.\n",
      "\n",
      "**Popular transformer models:**\n",
      "\n",
      "* **BERT:** Bidirectional Encoder Representations from Transformers\n",
      "* **GPT-3:** Generative Pre-trained Transformer 3\n",
      "* **T5:** Text-to-Text Transfer Transformer\n",
      "\n",
      "**HuggingFaceEmbeddings** likely uses pre-trained transformer models to generate vector representations of text, which is then stored and searched using FAISS. \n",
      "\n",
      "\n",
      "Let me know if you have any other questions!\n",
      " "
     ]
    }
   ],
   "source": [
    "for output in graph.stream(input):\n",
    "    for key,value in output.items():\n",
    "        #key==>node,value==>output\n",
    "        print(f\"here the output is '{key}':\")\n",
    "        print(\"----------\")\n",
    "        print(value,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_3(mass):\n",
    "    message=mass[\"message\"]\n",
    "    print(type(mass))\n",
    "    question=message[0]\n",
    "    print(question)\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass[\"message\"]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': []}"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "input={\"message\":[\"hello,how are you\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "hello,how are you\n"
     ]
    }
   ],
   "source": [
    "answer=function_3(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello,how are you'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1={\"message\":[\"hello,how is your job\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=function_3(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello,how is your job'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_detail=({\"name\":\"nithish\",\"age\":22})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'nithish', 'age': 22}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_detail[\"name\"]=\"kumar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'kumar', 'age': 22}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_detail"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
